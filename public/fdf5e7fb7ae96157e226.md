---
title: 近所の犬をトランプさんに飼わせてみた（AWSのSageMakerでStable Diffusion転移学習）
tags:
  - AWS
  - AI
  - SageMakerStudio
  - StableDiffusion
  - 記事投稿キャンペーン_ChatGPT
private: false
updated_at: '2023-03-25T17:52:23+09:00'
id: fdf5e7fb7ae96157e226
organization_url_name: kddi
---
これをやってみました。

https://aws.amazon.com/jp/blogs/news/fine-tune-text-to-image-stable-diffusion-models-with-amazon-sagemaker-jumpstart/


# これの何が嬉しいのか？

Stable Diffusionとはテキストから画像を生成するAIエンジンで、Webアプリも公式に提供されています。

https://stablediffusionweb.com/

このWeb版アプリにテキストを入れて画像を生成することができますが、 **生成が遅い** ・ **転移学習ができない** という弱みがあります。

AWSで提供されている機械学習プラットフォームSageMaker Studio（いわゆるJupyterLab環境）を使うことで、この2点の課題をクリアできます。
- 画像生成速度：公式Web版と違い、処理インスタンスサイズを調整することで生成スピードアップが可能。
- 転移学習：「この画像を読み込ませて、次の画像生成のインプットとして利用する」ことが容易になります。マシンスペックの課題をクラウドリソースで解決し、さらにSageMakerサービス内でテスト済みのトレーニングスクリプトを提供してくれることにより利用ハードルを下げています。


# 手順前編：とりあえず画像生成できるようになるまで

### Stable Diffusionモデルにアクセス

- AWSマネジメントコンソールにログインし、SageMakerにアクセス。
- 左ペインからStudioを選択し、ユーザープロファイルを選んで「Studioを開く」をクリック。
![スクリーンショット 2023-03-25 14.42.45.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/0d85fb8f-f343-bb3d-14aa-a4687db17a55.png)
- Studio UIが起動したら、左カラムのSageMaker JumpStartからModels, notebooks, solutionsを開き、中央に表示されるStable Diffusion 2.1 baseをクリック。
![スクリーンショット 2023-03-25 14.49.34.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/68fcb6dd-f2d5-b721-e0b8-9878399fb6b9.png)

### モデルのトレーニング＆デプロイを実施

- Train Modelからトレーニングを実施。お財布に余裕がある人はDeployment Configurationからインスタンスタイプをml.g4dn.16xlarge（デフォルトの倍スペック）へ変更してTrainボタンを押す。Completeになるまで20分ぐらいかかりました。
![スクリーンショット 2023-03-25 14.55.24.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/99b711e1-abfb-3100-c3d6-68851d83a5b9.png)
- 学習が完了したら、Deploy Modelセクションへスクロールしてデフォルト設定のままDeployボタンを押す。こちらも10分ほどかかります。
![スクリーンショット 2023-03-25 15.25.59.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/ca12390f-f975-3519-3ed4-95568ad1aa12.png)

### エンドポイントを起動してNotebookを実行

- Endpoint StatusがIn Serviceになったら、Use Endpoint from Studioセクションの「Open Notebook」を押す。これの起動処理にも少し時間がかかります。
![スクリーンショット 2023-03-25 15.49.59.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/08b8b5f2-001c-d7cc-05ac-782211cad8a1.png)
- 画面上部の準備中通知が消えたら、ツールバーの▶︎ボタンを何度か押してノートブック内のスクリプトを順番に実行していきます。コードブロックの[4]番目「Query Stable Diffusion Endpoint」を実行すると数十秒待たされたあと、画像が生成されます。
![スクリーンショット 2023-03-25 16.01.30.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/1b19fe34-d796-6140-f343-23b6c887a525.png)

### 任意のテキストで画像を生成してみる

- 前述のコードブロック[4]内のクエリーテキストを変更し、再度▶︎実行することで任意の画像を生成できます。
![スクリーンショット 2023-03-25 16.03.59.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/396fd701-a9f4-100c-633c-af8f98dd5623.png)


# 手順後編：サンプル画像でファインチューニングしてみる

冒頭で紹介した転移学習を試せるよう、「犬の面白い画像を作る」サンプルノードブックが提供されているので使ってみます。

- 左カラムのSageMaker JumpStartからModels, notebooks, solutionsを再度開き、検索バーに「fun」と入力し「Generate fun image of your dog」ノートブックを開く。
- 自分の環境でこれを実行できるように画面上部の「Import notebook」を実行。
![スクリーンショット 2023-03-25 16.11.19.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/4d0baec5-5a55-fdb0-5634-1950d80c28e1.png)

### 学習用の画像をアップロード

- ノートブックの実行前に事前準備をします。記載されているとおり自分の持っている犬の画像をSageMaker Studioのローカル環境内にアップロードします。自分のiCloud写真ライブラリーを「犬」で検索してみると、奇跡的に5枚ぐらいあったので活用してみます。
![スクリーンショット 2023-03-25 16.16.37.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/9bee819b-8a8c-123f-584d-840646ac95be.png)
- SageMaker Studio UI左側のフォルダーアイコンより、 `training_images` という名前のフォルダーを作成し手持ちの画像5枚をアップロードする。
![スクリーンショット 2023-03-25 16.19.16.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/72e16c17-7121-6c5e-6767-d5c3c511d75b.png)

### 実行前にコードを書き換える

- ノートブック実行時にサンプル画像ではなく自分のアップロード画像が使われるよう、コードブロック内の `use_local_images` を　`True` へ書き換える。
- また、すぐ下のコードブロック内の `instance_prompt` を自分のアップする写真の説明に書き換えておく。私は `A photo of my neiborhood dog` （近所の飼い犬）にしました。
![スクリーンショット 2023-03-25 16.24.15.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/16729f0b-e768-b979-8e4c-6e6b7f1e2300.png)
- 最後から2番目のコードブロック内に、学習させた画像を用いて新たに生成したい画像用のテキストが指定されているので、こちらも適宜修正します。私は近所の飼い犬が海にいたり、帽子をかぶっていたり、トランプさんと一緒にいたりすることにしました。
![スクリーンショット 2023-03-25 17.27.03.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/226d0515-e38e-fa95-b73f-2d7300852259.png)

### いざ学習＆画像生成

- すべて修正できたら、Notebookを上から順番に実行▶︎していきます。最後のコードブロックを実行するとエンドポイントが削除されてしまうので、通しで実行▶︎▶︎する際は注意。
- なお参考まで、私はS3バケット作成時に最初エラーが出ました。リージョン内に元々バケットが多すぎたせいでクォータに引っかかっていたので、不要バケットを削除しリランすると解消しました。

# そして生成された画像がこちら！

### 元ネタ

@minorun365 の近所の犬
![5.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/97ff72a5-4b1d-c737-bd93-d27251eb8a65.png)
↓

近所の犬 on the sea
![ダウンロード.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/5a25c130-3360-e19d-5d77-273a95565763.png)

近所の犬 with a hat
![ダウンロード (1).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/41d3d60f-fab6-b7c6-1857-22ad0471a15e.png)

近所の犬 with Donald Trump
![ダウンロード (2).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1633856/8c919d1b-dfff-a288-5335-7f1047f0d353.png)

**すげえええええ！！**
帽子はうまく出現しませんでしたが、近所のアノ犬がトランプさんに飼われている姿は壮観ですね。
